{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LSTM_Tuning.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"NsVqqLsCfdSJ","colab_type":"text"},"source":["# Hyper-parameter tuning for GloVe embedding and LSTM network"]},{"cell_type":"markdown","metadata":{"id":"-udvPq1iJ11F","colab_type":"text"},"source":["### Set up environnent, access to google drive, import librairies\n"]},{"cell_type":"code","metadata":{"id":"Z82p8EF0_c6X","colab_type":"code","outputId":"0b9b097a-446e-4f30-9592-2efa9bcba110","executionInfo":{"status":"ok","timestamp":1576686477782,"user_tz":-60,"elapsed":1058,"user":{"displayName":"Pedrotti Benjamin","photoUrl":"","userId":"07002540350929640587"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"l1yEtNy__h1G","colab_type":"code","colab":{}},"source":["%tensorflow_version 2.x"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QPIAX7zQIXla","colab_type":"text"},"source":["### Import librairies"]},{"cell_type":"code","metadata":{"id":"vLKe7zaw_ieM","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","import os, sys\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('Problem with GPU device')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WADKxhWk_kts","colab_type":"code","outputId":"b6dd75a7-87ea-4370-8386-811a4f256348","executionInfo":{"status":"ok","timestamp":1576686484587,"user_tz":-60,"elapsed":1027,"user":{"displayName":"Pedrotti Benjamin","photoUrl":"","userId":"07002540350929640587"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from __future__ import print_function\n","sys.path.insert(0, os.path.abspath('/content/drive/My Drive/ML_Project_2/'))\n","import sys, os\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import time\n","from tensorflow.keras.preprocessing.text import text_to_word_sequence\n","import gensim\n","from helpers import *\n","from models_LSTM import *\n","from multiprocessing import Pool\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from tensorflow.keras.models import load_model\n","from tensorflow.python.keras.layers.embeddings import Embedding\n","from sklearn import model_selection\n","from sklearn.model_selection import train_test_split\n","from keras.preprocessing.sequence import pad_sequences\n","import re\n","\n","tf.compat.v1.get_default_graph"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<function tensorflow.python.framework.ops.get_default_graph>"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"hNeWckZ1ALyG","colab_type":"code","colab":{}},"source":["# Define path to Google Drive \n","path_pr = \"/content/drive/My Drive/ML_Project_2/\""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"shSSV_DZIiyH","colab_type":"text"},"source":["### Define useful functions\n"]},{"cell_type":"code","metadata":{"id":"a_QuDCsC_wBY","colab_type":"code","colab":{}},"source":["def not_processing(data_train, data_test):\n","    \"\"\"\n","    Apply negation processing \n","\n","    :param data_train: Training dataset\n","    :param data_test: Test dataset\n","    :return: Training and test dataset with negation processing\n","    \"\"\"\n","    for idx, tweet in enumerate(data_train):\n","        tweet = ' '.join(tweet)\n","        data_train[idx] = re.sub(r\"\\w+n't\\s?\", 'not ', tweet)\n","\n","    for idx, tweet in enumerate(data_test):\n","        tweet = ' '.join(tweet)\n","        data_test[idx] = re.sub(r\"\\w+n't\\s?\", 'not ', tweet)\n","\n","    to_not = ['havent', 'doesnt', 'cant', 'dont', 'shouldnt', 'arent', 'couldnt', \"didnt\", \"hadnt\", \"mightnt\",\n","              \"mustnt\", \"neednt\", \"wasnt\", \"wont\", \"wouldnt\", 'neednt', 'isnt', 'werent']\n","\n","    for word in to_not:\n","        data_train = [re.sub(r'\\b' + word + r'\\b', 'not', tweet) for tweet in data_train]\n","        data_test = [re.sub(r'\\b' + word + r'\\b', 'not', tweet) for tweet in data_test]\n","\n","    return data_train, data_test\n","\n","\n","def tokenize(data_train, data_test, len_max_tweet, n_dim):\n","    \"\"\"\n","    Tokenize tweets and load embedding matrix\n","    \n","    :param data_train: Training dataset\n","    :param data_test: Test dataset\n","    :param len_max_tweet: Maximum length of the tweets in the datasets\n","    :param n_dim: Embedding dimension\n","    :return: Tokenized training and test dataset, size of the dataset vocabulary and embedding matrix\n","    \"\"\"\n","    # Create a tokenizer instance\n","    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=1e6)\n","\n","    # Fit the tokenizer on the training set\n","    tokenizer.fit_on_texts(data_train)\n","\n","    # Tokenize data\n","    data_train = tokenizer.texts_to_sequences(data_train)\n","    data_test = tokenizer.texts_to_sequences(data_test)\n","\n","    # Compute vocabulary size\n","    vocab_size = len(tokenizer.word_index) + 1\n","\n","    embeddings_dictionary = dict()\n","    glove_file = open(path_pr + 'glove/glove.twitter.27B.' + str(n_dim) + 'd.txt', encoding=\"utf8\")\n","\n","    # Extract glove matrix \n","    for line in glove_file:\n","        records = line.split()\n","        word = records[0]\n","        vector_dimensions = np.asarray(records[1:], dtype='float32')\n","        embeddings_dictionary[word] = vector_dimensions\n","    glove_file.close()\n","\n","    embedding_matrix = np.zeros((vocab_size, n_dim))\n","    for word, index in tokenizer.word_index.items():\n","        embedding_vector = embeddings_dictionary.get(word)\n","        if embedding_vector is not None:\n","            embedding_matrix[index] = embedding_vector\n","\n","    return data_train, data_test, vocab_size, embedding_matrix"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fOtqswQV3ag2","colab_type":"text"},"source":["### Load data"]},{"cell_type":"code","metadata":{"id":"aR7zfrPW_ykh","colab_type":"code","outputId":"faee3347-db1f-420c-978c-a66808b07bb4","executionInfo":{"status":"ok","timestamp":1576686497942,"user_tz":-60,"elapsed":3533,"user":{"displayName":"Pedrotti Benjamin","photoUrl":"","userId":"07002540350929640587"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(\"Loading Data ...\")\n","# Load full dataset or not: 'f' or 'nf'\n","full='nf'\n","processed=False\n","\n","if processed:\n","    data_train = np.load(path_pr + 'Processed_Data_1/lem_data_nf.npy', allow_pickle=True)\n","    data_test = np.load(path_pr + 'Processed_Data_1/lem_data_test.npy', allow_pickle=True)\n","    labels = np.load(path_pr + 'Processed_Data_1/labels_train_nf.npy', allow_pickle=True)\n","    dataset_type = 'processed'\n","\n","else:\n","    data_train = np.load('/content/drive/My Drive/ML_Project_2/Processed_Data/raw_data_train_' + full + '.npy', allow_pickle=True)\n","    data_test = np.load('/content/drive/My Drive/ML_Project_2/Processed_Data/raw_data_test' + '.npy', allow_pickle=True)\n","    labels = np.load('/content/drive/My Drive/ML_Project_2/Processed_Data/labels_train_'+ full +'_sl5.npy')\n","    dataset_type = 'raw'\n","\n","# If labels are -1 instead of 0\n","labels = np.where(labels == -1, 0, labels)\n","\n"],"execution_count":29,"outputs":[{"output_type":"stream","text":["Loading Data ...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pmBU18ye1aCS","colab_type":"code","colab":{}},"source":["# To train without the full set\n","n_train = -1\n","\n","if n_train > 0:\n","    data_train = data_train[:n_train]\n","    labels = labels[:n_train]\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IS1xOeTE1hDF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"62fc982a-85b8-4fc2-a228-84eb302680ca","executionInfo":{"status":"ok","timestamp":1576686502955,"user_tz":-60,"elapsed":1466,"user":{"displayName":"Pedrotti Benjamin","photoUrl":"","userId":"07002540350929640587"}}},"source":["print(\"Computing len_max_tweet\", flush=True)\n","\n","# Max length of tweet (after removed not in vocab words)\n","len_max_tweet = np.max([len(tweet) for tweet in data_train])\n","len_max_tweet = np.max((len_max_tweet, np.max([len(tweet) for tweet in data_test])))"],"execution_count":31,"outputs":[{"output_type":"stream","text":["Computing len_max_tweet\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2Y8iXZxJ_020","colab_type":"code","outputId":"6a48f708-fd80-4b78-8f43-f18587a9d0d9","executionInfo":{"status":"ok","timestamp":1576686514653,"user_tz":-60,"elapsed":8862,"user":{"displayName":"Pedrotti Benjamin","photoUrl":"","userId":"07002540350929640587"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(\"Start to convert negative words\", flush=True)\n","\n","# Negation processing\n","data_train_not, data_test_not = not_processing(data_train, data_test)\n"],"execution_count":32,"outputs":[{"output_type":"stream","text":["Start to convert negative words\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IfxmT7494AN8","colab_type":"text"},"source":["### Define callback for the hyperparameter"]},{"cell_type":"code","metadata":{"id":"jP5bNiZHKX2T","colab_type":"code","colab":{}},"source":["from keras.callbacks import ModelCheckpoint, LearningRateScheduler, Callback\n","\n","class GetAcc(Callback):\n","    def __init__(self, data_test, labels_test, acc_array, kfold_idx):\n","        self.data_test = data_test\n","        self.labels_test = labels_test\n","        self.acc = acc_array\n","        self.kfold_idx = kfold_idx\n","\n","    def on_epoch_end(self, epoch, logs={}):\n","        loss, accuracy = self.model.evaluate(self.data_test, self.labels_test, verbose=0)\n","        self.acc[self.kfold_idx, epoch] = accuracy\n","        #print('kfold_idx:', self.kfold_idx, ' Epochs #', epoch)\n","        #print('\\nTesting loss: {}, acc: {}\\n'.format(loss, accuracy))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hhKwc5n_HKJo","colab_type":"text"},"source":["### Hyperparameter tuning"]},{"cell_type":"code","metadata":{"id":"HHtucwja_79N","colab_type":"code","outputId":"c3a8539b-ebfc-478c-a6c7-d0018b2ee4ab","executionInfo":{"status":"error","timestamp":1576689830006,"user_tz":-60,"elapsed":2835380,"user":{"displayName":"Pedrotti Benjamin","photoUrl":"","userId":"07002540350929640587"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["from sklearn.model_selection import train_test_split, KFold, cross_val_score\n","\n","results = pd.DataFrame(columns=['ed', 'nf', 'lr', 'bs', 'ep', 'accuracy', 'mean_accuracy', 'std_accuracy'])\n","\n","# Number of k-folds\n","n_splits = 10\n","\n","# Define parameters to tune \n","epochs = 9\n","filters_arr = [400]\n","n_dims = [200]\n","lr = 1e-3;\n","batch_sizes = [64, 128]\n","\n","for n_dim in n_dims:\n","  print('ndim = ', n_dim)\n","\n","  data_test = data_test_not.copy()\n","  data_train, y_train = data_train_not.copy(), labels.copy()\n","\n","  data_train, data_test, vocab_size, embedding_matrix = tokenize(data_train, data_test, len_max_tweet, n_dim)\n","\n","  data_train = pad_sequences(data_train, padding='post', maxlen=len_max_tweet)\n","  data_test = pad_sequences(data_test, padding='post', maxlen=len_max_tweet)\n","\n","  for filters in filters_arr:\n","      print('filter = ', filters)\n","\n","      for batch_size in batch_sizes:\n","        print('batch_size = ', batch_size)\n","\n","        acc_array = np.zeros((n_splits, epochs))\n","        k_i = 0\n","\n","        for train_index, test_index in KFold(n_splits).split(data_train):\n","            x_train, x_test = data_train[train_index], data_train[test_index]\n","            y_train_, y_test = y_train[train_index], y_train[test_index]    \n","            \n","            model = build_model_lstm_emb(filters, vocab_size, n_dim, embedding_matrix, len_max_tweet, lr)\n","            \n","            if (k_i == 0):\n","              model.summary()\n","\n","            print('k_fold:', k_i)\n","\n","            model.fit(x_train, y_train_,\n","                    batch_size=batch_size,\n","                    epochs=epochs,\n","                    validation_data=(x_test, y_test),\n","                    callbacks=[GetAcc(x_test, y_test, acc_array, k_i)])\n","            k_i += 1\n","\n","        for n in range(epochs):\n","            results = results.append({'ed': n_dim, 'nf': filters, 'lr': lr, 'bs': batch_size, 'ep': n+1,\n","                                        'accuracy': acc_array[:, n], 'mean_accuracy': np.mean(acc_array[:, n]), \n","                                        'std_accuracy': np.std(acc_array[:, n])}, ignore_index=True)\n","\n","imax = results['mean_accuracy'].idxmax()\n","print(\"Best: %f using \\n %s\" % (results['mean_accuracy'].iloc[imax], results.iloc[imax]))\n"],"execution_count":35,"outputs":[{"output_type":"stream","text":["ndim =  200\n","filter =  400\n","batch_size =  64\n","Model: \"sequential_26\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_26 (Embedding)     (None, 49, 200)           18761400  \n","_________________________________________________________________\n","lstm_26 (LSTM)               (None, 400)               961600    \n","_________________________________________________________________\n","dense_26 (Dense)             (None, 1)                 401       \n","=================================================================\n","Total params: 19,723,401\n","Trainable params: 962,001\n","Non-trainable params: 18,761,400\n","_________________________________________________________________\n","k_fold: 0\n","Train on 163188 samples, validate on 18133 samples\n","Epoch 1/9\n","163188/163188 [==============================] - 32s 195us/sample - loss: 0.4463 - accuracy: 0.7860 - val_loss: 0.5175 - val_accuracy: 0.7382\n","Epoch 2/9\n","163188/163188 [==============================] - 30s 186us/sample - loss: 0.3816 - accuracy: 0.8250 - val_loss: 0.5472 - val_accuracy: 0.7166\n","Epoch 3/9\n","163188/163188 [==============================] - 30s 186us/sample - loss: 0.3565 - accuracy: 0.8398 - val_loss: 0.3779 - val_accuracy: 0.8162\n","Epoch 4/9\n","163188/163188 [==============================] - 30s 186us/sample - loss: 0.3305 - accuracy: 0.8531 - val_loss: 0.4526 - val_accuracy: 0.7909\n","Epoch 5/9\n","163188/163188 [==============================] - 31s 189us/sample - loss: 0.2977 - accuracy: 0.8706 - val_loss: 0.4001 - val_accuracy: 0.8270\n","Epoch 6/9\n","163188/163188 [==============================] - 31s 188us/sample - loss: 0.2576 - accuracy: 0.8912 - val_loss: 0.4317 - val_accuracy: 0.8143\n","Epoch 7/9\n","163188/163188 [==============================] - 31s 187us/sample - loss: 0.2114 - accuracy: 0.9137 - val_loss: 0.4494 - val_accuracy: 0.8065\n","Epoch 8/9\n","163188/163188 [==============================] - 31s 188us/sample - loss: 0.1708 - accuracy: 0.9322 - val_loss: 0.5469 - val_accuracy: 0.7859\n","Epoch 9/9\n","163188/163188 [==============================] - 31s 187us/sample - loss: 0.1344 - accuracy: 0.9485 - val_loss: 0.7115 - val_accuracy: 0.7636\n","k_fold: 1\n","Train on 163189 samples, validate on 18132 samples\n","Epoch 1/9\n","163189/163189 [==============================] - 32s 194us/sample - loss: 0.5337 - accuracy: 0.7222 - val_loss: 0.6186 - val_accuracy: 0.6706\n","Epoch 2/9\n","163189/163189 [==============================] - 30s 186us/sample - loss: 0.3874 - accuracy: 0.8224 - val_loss: 0.4645 - val_accuracy: 0.7630\n","Epoch 3/9\n","163189/163189 [==============================] - 30s 187us/sample - loss: 0.3599 - accuracy: 0.8380 - val_loss: 0.4671 - val_accuracy: 0.7799\n","Epoch 4/9\n","163189/163189 [==============================] - 30s 186us/sample - loss: 0.3341 - accuracy: 0.8518 - val_loss: 0.4091 - val_accuracy: 0.8008\n","Epoch 5/9\n","163189/163189 [==============================] - 30s 186us/sample - loss: 0.3056 - accuracy: 0.8662 - val_loss: 0.5157 - val_accuracy: 0.7572\n","Epoch 6/9\n","163189/163189 [==============================] - 31s 188us/sample - loss: 0.2666 - accuracy: 0.8863 - val_loss: 0.4518 - val_accuracy: 0.7998\n","Epoch 7/9\n","163189/163189 [==============================] - 30s 186us/sample - loss: 0.2234 - accuracy: 0.9066 - val_loss: 0.4917 - val_accuracy: 0.8003\n","Epoch 8/9\n","163189/163189 [==============================] - 30s 187us/sample - loss: 0.1973 - accuracy: 0.9185 - val_loss: 0.5468 - val_accuracy: 0.7734\n","Epoch 9/9\n","163189/163189 [==============================] - 30s 185us/sample - loss: 0.1559 - accuracy: 0.9391 - val_loss: 0.6384 - val_accuracy: 0.7854\n","k_fold: 2\n","Train on 163189 samples, validate on 18132 samples\n","Epoch 1/9\n","163189/163189 [==============================] - 32s 197us/sample - loss: 0.5172 - accuracy: 0.7240 - val_loss: 0.4617 - val_accuracy: 0.7767\n","Epoch 2/9\n","163189/163189 [==============================] - 30s 187us/sample - loss: 0.3882 - accuracy: 0.8219 - val_loss: 0.4713 - val_accuracy: 0.7583\n","Epoch 3/9\n","163189/163189 [==============================] - 30s 187us/sample - loss: 0.3620 - accuracy: 0.8363 - val_loss: 0.4365 - val_accuracy: 0.7871\n","Epoch 4/9\n","163189/163189 [==============================] - 30s 187us/sample - loss: 0.3362 - accuracy: 0.8497 - val_loss: 0.5265 - val_accuracy: 0.7317\n","Epoch 5/9\n","163189/163189 [==============================] - 30s 187us/sample - loss: 0.3041 - accuracy: 0.8668 - val_loss: 0.4452 - val_accuracy: 0.7949\n","Epoch 6/9\n","163189/163189 [==============================] - 30s 186us/sample - loss: 0.2623 - accuracy: 0.8879 - val_loss: 0.5265 - val_accuracy: 0.7737\n","Epoch 7/9\n","163189/163189 [==============================] - 31s 190us/sample - loss: 0.2132 - accuracy: 0.9123 - val_loss: 0.5014 - val_accuracy: 0.7920\n","Epoch 8/9\n","163189/163189 [==============================] - 30s 187us/sample - loss: 0.1660 - accuracy: 0.9335 - val_loss: 0.7390 - val_accuracy: 0.7564\n","Epoch 9/9\n","163189/163189 [==============================] - 31s 187us/sample - loss: 0.1261 - accuracy: 0.9514 - val_loss: 0.6787 - val_accuracy: 0.7986\n","k_fold: 3\n","Train on 163189 samples, validate on 18132 samples\n","Epoch 1/9\n","163189/163189 [==============================] - 32s 197us/sample - loss: 0.5150 - accuracy: 0.7241 - val_loss: 0.4316 - val_accuracy: 0.7791\n","Epoch 2/9\n","163189/163189 [==============================] - 30s 186us/sample - loss: 0.3872 - accuracy: 0.8224 - val_loss: 0.4279 - val_accuracy: 0.7770\n","Epoch 3/9\n","163189/163189 [==============================] - 30s 186us/sample - loss: 0.3624 - accuracy: 0.8358 - val_loss: 0.4786 - val_accuracy: 0.7803\n","Epoch 4/9\n","163189/163189 [==============================] - 30s 186us/sample - loss: 0.3381 - accuracy: 0.8493 - val_loss: 0.4281 - val_accuracy: 0.7790\n","Epoch 5/9\n","163189/163189 [==============================] - 30s 187us/sample - loss: 0.3097 - accuracy: 0.8637 - val_loss: 0.3921 - val_accuracy: 0.8068\n","Epoch 6/9\n","163189/163189 [==============================] - 30s 187us/sample - loss: 0.2734 - accuracy: 0.8824 - val_loss: 0.3822 - val_accuracy: 0.8305\n","Epoch 7/9\n","163189/163189 [==============================] - 30s 186us/sample - loss: 0.2313 - accuracy: 0.9037 - val_loss: 0.5872 - val_accuracy: 0.7635\n","Epoch 8/9\n","163189/163189 [==============================] - 31s 189us/sample - loss: 0.1878 - accuracy: 0.9247 - val_loss: 0.5679 - val_accuracy: 0.7937\n","Epoch 9/9\n","163189/163189 [==============================] - 30s 186us/sample - loss: 0.1484 - accuracy: 0.9426 - val_loss: 0.6484 - val_accuracy: 0.7847\n","k_fold: 4\n","Train on 163189 samples, validate on 18132 samples\n","Epoch 1/9\n","163189/163189 [==============================] - 32s 194us/sample - loss: 0.4331 - accuracy: 0.7984 - val_loss: 0.5889 - val_accuracy: 0.6748\n","Epoch 2/9\n","163189/163189 [==============================] - 31s 187us/sample - loss: 0.3818 - accuracy: 0.8275 - val_loss: 0.4945 - val_accuracy: 0.7316\n","Epoch 3/9\n","163189/163189 [==============================] - 30s 185us/sample - loss: 0.3559 - accuracy: 0.8404 - val_loss: 0.4971 - val_accuracy: 0.7413\n","Epoch 4/9\n","163189/163189 [==============================] - 30s 185us/sample - loss: 0.3296 - accuracy: 0.8543 - val_loss: 0.3543 - val_accuracy: 0.8474\n","Epoch 5/9\n","163189/163189 [==============================] - 30s 185us/sample - loss: 0.2968 - accuracy: 0.8720 - val_loss: 0.3880 - val_accuracy: 0.8069\n","Epoch 6/9\n","163189/163189 [==============================] - 30s 186us/sample - loss: 0.2581 - accuracy: 0.8926 - val_loss: 0.5321 - val_accuracy: 0.7765\n","Epoch 7/9\n","163189/163189 [==============================] - 30s 185us/sample - loss: 0.2173 - accuracy: 0.9118 - val_loss: 0.5415 - val_accuracy: 0.7715\n","Epoch 8/9\n","163189/163189 [==============================] - 30s 185us/sample - loss: 0.1806 - accuracy: 0.9281 - val_loss: 0.5367 - val_accuracy: 0.7847\n","Epoch 9/9\n","163189/163189 [==============================] - 31s 187us/sample - loss: 0.1489 - accuracy: 0.9415 - val_loss: 0.6297 - val_accuracy: 0.8061\n","k_fold: 5\n","Train on 163189 samples, validate on 18132 samples\n","Epoch 1/9\n","163189/163189 [==============================] - 32s 194us/sample - loss: 0.4378 - accuracy: 0.7895 - val_loss: 0.3908 - val_accuracy: 0.8425\n","Epoch 2/9\n","163189/163189 [==============================] - 30s 186us/sample - loss: 0.3848 - accuracy: 0.8231 - val_loss: 0.3880 - val_accuracy: 0.8294\n","Epoch 3/9\n","163189/163189 [==============================] - 30s 186us/sample - loss: 0.3640 - accuracy: 0.8336 - val_loss: 0.3575 - val_accuracy: 0.8409\n","Epoch 4/9\n","163189/163189 [==============================] - 30s 185us/sample - loss: 0.3364 - accuracy: 0.8483 - val_loss: 0.4060 - val_accuracy: 0.8099\n","Epoch 5/9\n","163189/163189 [==============================] - 30s 186us/sample - loss: 0.3129 - accuracy: 0.8614 - val_loss: 0.4303 - val_accuracy: 0.8173\n","Epoch 6/9\n","163189/163189 [==============================] - 30s 186us/sample - loss: 0.2757 - accuracy: 0.8803 - val_loss: 0.3668 - val_accuracy: 0.8551\n","Epoch 7/9\n","163189/163189 [==============================] - 30s 186us/sample - loss: 0.2381 - accuracy: 0.9001 - val_loss: 0.5022 - val_accuracy: 0.8011\n","Epoch 8/9\n","163189/163189 [==============================] - 30s 186us/sample - loss: 0.1985 - accuracy: 0.9182 - val_loss: 0.4658 - val_accuracy: 0.8283\n","Epoch 9/9\n","163189/163189 [==============================] - 30s 187us/sample - loss: 0.1575 - accuracy: 0.9368 - val_loss: 0.5311 - val_accuracy: 0.8225\n","k_fold: 6\n","Train on 163189 samples, validate on 18132 samples\n","Epoch 1/9\n","163189/163189 [==============================] - 32s 195us/sample - loss: 0.4357 - accuracy: 0.7931 - val_loss: 0.5391 - val_accuracy: 0.7965\n","Epoch 2/9\n","163189/163189 [==============================] - 31s 190us/sample - loss: 0.3831 - accuracy: 0.8237 - val_loss: 0.3879 - val_accuracy: 0.8400\n","Epoch 3/9\n","163189/163189 [==============================] - 31s 187us/sample - loss: 0.3576 - accuracy: 0.8368 - val_loss: 0.3869 - val_accuracy: 0.8217\n","Epoch 4/9\n","163189/163189 [==============================] - 31s 189us/sample - loss: 0.3319 - accuracy: 0.8498 - val_loss: 0.3939 - val_accuracy: 0.8482\n","Epoch 5/9\n","163189/163189 [==============================] - 31s 188us/sample - loss: 0.3011 - accuracy: 0.8666 - val_loss: 0.3974 - val_accuracy: 0.8648\n","Epoch 6/9\n","163189/163189 [==============================] - 31s 187us/sample - loss: 0.2621 - accuracy: 0.8867 - val_loss: 0.4728 - val_accuracy: 0.7932\n","Epoch 7/9\n","163189/163189 [==============================] - 31s 189us/sample - loss: 0.2234 - accuracy: 0.9058 - val_loss: 0.5561 - val_accuracy: 0.7921\n","Epoch 8/9\n","163189/163189 [==============================] - 31s 188us/sample - loss: 0.2034 - accuracy: 0.9137 - val_loss: 0.3770 - val_accuracy: 0.8424\n","Epoch 9/9\n","163189/163189 [==============================] - 31s 188us/sample - loss: 0.1838 - accuracy: 0.9242 - val_loss: 0.5511 - val_accuracy: 0.8052\n","k_fold: 7\n","Train on 163189 samples, validate on 18132 samples\n","Epoch 1/9\n","163189/163189 [==============================] - 32s 194us/sample - loss: 0.5762 - accuracy: 0.6416 - val_loss: 0.5481 - val_accuracy: 0.7478\n","Epoch 2/9\n","163189/163189 [==============================] - 30s 187us/sample - loss: 0.4074 - accuracy: 0.8077 - val_loss: 0.4840 - val_accuracy: 0.7820\n","Epoch 3/9\n","163189/163189 [==============================] - 31s 189us/sample - loss: 0.3790 - accuracy: 0.8244 - val_loss: 0.3341 - val_accuracy: 0.8643\n","Epoch 4/9\n","163189/163189 [==============================] - 30s 186us/sample - loss: 0.3573 - accuracy: 0.8364 - val_loss: 0.4494 - val_accuracy: 0.7979\n","Epoch 5/9\n","163189/163189 [==============================] - 31s 188us/sample - loss: 0.3332 - accuracy: 0.8479 - val_loss: 0.3971 - val_accuracy: 0.8272\n","Epoch 6/9\n","163189/163189 [==============================] - 31s 187us/sample - loss: 0.3022 - accuracy: 0.8654 - val_loss: 0.4438 - val_accuracy: 0.8095\n","Epoch 7/9\n","163189/163189 [==============================] - 30s 186us/sample - loss: 0.2630 - accuracy: 0.8859 - val_loss: 0.4352 - val_accuracy: 0.8169\n","Epoch 8/9\n","163189/163189 [==============================] - 30s 186us/sample - loss: 0.2174 - accuracy: 0.9085 - val_loss: 0.4723 - val_accuracy: 0.8242\n","Epoch 9/9\n","163189/163189 [==============================] - 30s 186us/sample - loss: 0.1720 - accuracy: 0.9302 - val_loss: 0.4316 - val_accuracy: 0.8556\n","k_fold: 8\n","Train on 163189 samples, validate on 18132 samples\n","Epoch 1/9\n","163189/163189 [==============================] - 32s 194us/sample - loss: 0.4692 - accuracy: 0.7620 - val_loss: 0.4914 - val_accuracy: 0.7695\n","Epoch 2/9\n","163189/163189 [==============================] - 30s 187us/sample - loss: 0.3849 - accuracy: 0.8206 - val_loss: 0.3360 - val_accuracy: 0.8773\n","Epoch 3/9\n","163189/163189 [==============================] - 30s 186us/sample - loss: 0.3596 - accuracy: 0.8349 - val_loss: 0.3808 - val_accuracy: 0.8336\n","Epoch 4/9\n","163189/163189 [==============================] - 31s 190us/sample - loss: 0.3346 - accuracy: 0.8483 - val_loss: 0.4191 - val_accuracy: 0.8146\n","Epoch 5/9\n","163189/163189 [==============================] - 31s 187us/sample - loss: 0.3058 - accuracy: 0.8638 - val_loss: 0.4202 - val_accuracy: 0.8131\n","Epoch 6/9\n","163189/163189 [==============================] - 31s 188us/sample - loss: 0.2691 - accuracy: 0.8830 - val_loss: 0.4095 - val_accuracy: 0.8271\n","Epoch 7/9\n","163189/163189 [==============================] - 30s 187us/sample - loss: 0.2276 - accuracy: 0.9036 - val_loss: 0.5368 - val_accuracy: 0.7826\n","Epoch 8/9\n","163189/163189 [==============================] - 30s 186us/sample - loss: 0.1849 - accuracy: 0.9244 - val_loss: 0.4933 - val_accuracy: 0.8355\n","Epoch 9/9\n","163189/163189 [==============================] - 30s 186us/sample - loss: 0.1454 - accuracy: 0.9418 - val_loss: 0.7299 - val_accuracy: 0.7867\n","k_fold: 9\n","Train on 163189 samples, validate on 18132 samples\n","Epoch 1/9\n","163189/163189 [==============================] - 32s 194us/sample - loss: 0.4434 - accuracy: 0.7858 - val_loss: 0.4975 - val_accuracy: 0.7481\n","Epoch 2/9\n","163189/163189 [==============================] - 30s 186us/sample - loss: 0.3868 - accuracy: 0.8203 - val_loss: 0.3966 - val_accuracy: 0.8389\n","Epoch 3/9\n","163189/163189 [==============================] - 30s 187us/sample - loss: 0.3620 - accuracy: 0.8329 - val_loss: 0.4083 - val_accuracy: 0.7972\n","Epoch 4/9\n","163189/163189 [==============================] - 30s 186us/sample - loss: 0.3408 - accuracy: 0.8445 - val_loss: 0.3554 - val_accuracy: 0.8721\n","Epoch 5/9\n","163189/163189 [==============================] - 31s 189us/sample - loss: 0.3214 - accuracy: 0.8550 - val_loss: 0.4101 - val_accuracy: 0.7964\n","Epoch 6/9\n","163189/163189 [==============================] - 31s 188us/sample - loss: 0.2879 - accuracy: 0.8725 - val_loss: 0.4802 - val_accuracy: 0.7884\n","Epoch 7/9\n","163189/163189 [==============================] - 31s 187us/sample - loss: 0.2456 - accuracy: 0.8948 - val_loss: 0.3295 - val_accuracy: 0.8693\n","Epoch 8/9\n","163189/163189 [==============================] - 30s 186us/sample - loss: 0.1953 - accuracy: 0.9184 - val_loss: 0.5548 - val_accuracy: 0.8010\n","Epoch 9/9\n","163189/163189 [==============================] - 30s 186us/sample - loss: 0.1486 - accuracy: 0.9402 - val_loss: 0.5493 - val_accuracy: 0.8139\n","batch_size =  128\n","Model: \"sequential_36\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_36 (Embedding)     (None, 49, 200)           18761400  \n","_________________________________________________________________\n","lstm_36 (LSTM)               (None, 400)               961600    \n","_________________________________________________________________\n","dense_36 (Dense)             (None, 1)                 401       \n","=================================================================\n","Total params: 19,723,401\n","Trainable params: 962,001\n","Non-trainable params: 18,761,400\n","_________________________________________________________________\n","k_fold: 0\n","Train on 163188 samples, validate on 18133 samples\n","Epoch 1/9\n"," 45952/163188 [=======>......................] - ETA: 22s - loss: 0.5078 - accuracy: 0.7455"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-35-b57c160ce0c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                     callbacks=[GetAcc(x_test, y_test, acc_array, k_i)])\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0mk_i\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n","\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"bIHw4i82WLGZ","colab_type":"code","outputId":"7c934849-6405-417e-9b28-3b85a7261bd6","executionInfo":{"status":"ok","timestamp":1576689849817,"user_tz":-60,"elapsed":1078,"user":{"displayName":"Pedrotti Benjamin","photoUrl":"","userId":"07002540350929640587"}},"colab":{"base_uri":"https://localhost:8080/","height":461}},"source":["imax = np.argmax(results['mean_accuracy'].values)\n","print(\"Best: %f using \\n %s\" % (results['mean_accuracy'].iloc[imax], results.iloc[imax]))\n","\n","\n","\n","import numpy as np \n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","x = results['accuracy'].iloc[imax]\n","np.save(path_pr + 'results_LSTM_raw', x)\n","sns.set('talk', 'whitegrid', 'dark', font_scale=0.8, font='Ricty',\n","        rc={\"lines.linewidth\": 2, 'grid.linestyle': '--'})\n","\n","plt.boxplot(x)\n","plt.show\n"],"execution_count":36,"outputs":[{"output_type":"stream","text":["Best: 0.811141 using \n"," ed                                                             200\n","nf                                                             400\n","lr                                                           0.001\n","bs                                                              64\n","ep                                                               5\n","accuracy         [0.8270004987716675, 0.7571696639060974, 0.794...\n","mean_accuracy                                             0.811141\n","std_accuracy                                             0.0261867\n","Name: 4, dtype: object\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<function matplotlib.pyplot.show>"]},"metadata":{"tags":[]},"execution_count":36},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYcAAAEBCAYAAACT92m7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIhIwOJARESC/w9KxhMyc9Gn6QAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"Yc8-WSHHGbLn","colab_type":"code","colab":{}},"source":["y_pred = np.ndarray.flatten(model.predict_classes(data_test, batch_size=batch_size))\n","\n","# Replace for submission\n","y_pred = np.where(y_pred == 0, -1, y_pred)\n","\n","# path_csv = 'Subs/'\n","csv_name = 'sub_tf_e' + str(epochs) + '_f' + str(filters) + '_bs' + str(batch_size) \\\n","           + '_hd' + str(hidden_dims) + '_ks' + str(kernel_size) + '_deep_' + type_model + 'flstm_' + str(filters_lstm)\n","\n","create_csv_submission(y_pred, csv_name + '.csv')\n","print(\"Output name:\", csv_name)"],"execution_count":0,"outputs":[]}]}